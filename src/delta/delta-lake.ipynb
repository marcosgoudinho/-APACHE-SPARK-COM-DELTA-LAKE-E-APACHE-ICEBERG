{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b3b351",
   "metadata": {},
   "source": [
    "# Delta Lake - Cen√°rio e Opera√ß√µes\n",
    "\n",
    "Este notebook descreve o uso do Delta Lake com Apache Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6816d4",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Modelo ER e Fonte de Dados\n",
    "\n",
    "Usaremos uma tabela `usuarios` com o seguinte esquema:\n",
    "\n",
    "- `id` (int)\n",
    "- `nome` (string)\n",
    "- `idade` (int)\n",
    "- `status` (string)\n",
    "\n",
    "A fonte de dados utilizada √© um arquivo CSV p√∫blico com dados de usu√°rios fict√≠cios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e771be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder     .appName(\"DeltaLakeExample\")     .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")     .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a210c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = spark.read.csv(\"data/usuarios.csv\", header=True, inferSchema=True)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bd0ca8",
   "metadata": {},
   "source": [
    "## üíæ Criando a tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/usuarios\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefcb5c",
   "metadata": {},
   "source": [
    "## ‚ûï Comando INSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "new_users = [Row(id=4, nome=\"Carlos\", idade=22, status=\"ativo\")]\n",
    "spark.createDataFrame(new_users).write.format(\"delta\").mode(\"append\").save(\"/tmp/delta/usuarios\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee5798",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Comando UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b35a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from delta.tables import DeltaTable\n",
    "delta_table = DeltaTable.forPath(spark, \"/tmp/delta/usuarios\")\n",
    "delta_table.update(\"idade < 18\", {\"idade\": \"18\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042aec68",
   "metadata": {},
   "source": [
    "## ‚ùå Comando DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c400cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delta_table.delete(\"status = 'inativo'\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}